{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cdb36e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12850621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\ainao\\\\Downloads\\\\Projects\\\\Fraud Detection\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e78065b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cc733c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\ainao\\\\Downloads\\\\Projects\\\\Fraud Detection'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "934ed4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "@dataclass\n",
    "class ModelTrainerConfig:\n",
    "    root_dir : Path\n",
    "    model_save_path : Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1af68171",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fraud_detection.utils.common import create_directories, read_yaml\n",
    "from fraud_detection.constants import *\n",
    "from fraud_detection.entity import DataTransformationConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41e551e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self, config_filepath=CONFIG_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_transformation(self) -> DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            train_path=config.train_path,\n",
    "            test_path=config.test_path,\n",
    "            train_data=config.train_data,\n",
    "            test_data=config.test_data,\n",
    "            preprocessor=config.preprocessor\n",
    "        )\n",
    "\n",
    "        return data_transformation_config\n",
    "\n",
    "    def get_model_trainer(self) -> ModelTrainerConfig:\n",
    "        config = self.config.model_trainer\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        model_trainer_config = ModelTrainerConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            model_save_path=config.model_save_path\n",
    "        )\n",
    "\n",
    "        return model_trainer_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e00eccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from fraud_detection.entity import DataTransformationConfig\n",
    "from fraud_detection.conponents.data_transformation import DataTransformation\n",
    "from fraud_detection.utils.common import save_object\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27ea85af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "class ModelTrainer:\n",
    "    def __init__(self, config, data_transformer):\n",
    "        self.config = config\n",
    "        self.data_transformer = data_transformer\n",
    "        self.models = self._initialize_models()\n",
    "\n",
    "    def _initialize_models(self):\n",
    "        return {\n",
    "            \"Logistic Regression\": LogisticRegression(random_state=42, max_iter=1000, class_weight=\"balanced\"),\n",
    "            \"Random Forest\": RandomForestClassifier(random_state=42, class_weight=\"balanced\", n_estimators=300),\n",
    "            \"XGBClassifier\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', scale_pos_weight=5, random_state=42),\n",
    "            \"CatBoostClassifier\": CatBoostClassifier(verbose=False, random_state=42, scale_pos_weight=5),\n",
    "            \"LightGBM\": LGBMClassifier(random_state=42, n_jobs=-1, class_weight=\"balanced\"),\n",
    "            \"AdaBoost Classifier\": AdaBoostClassifier(random_state=42),\n",
    "            \"Gradient Boosting Classifier\": GradientBoostingClassifier(random_state=42)\n",
    "        }\n",
    "\n",
    "    def _apply_smote(self, X, y):\n",
    "        smote = SMOTE(random_state=42)\n",
    "        return smote.fit_resample(X, y)\n",
    "\n",
    "    def train(self):\n",
    "        X_train, X_val, X_test, y_train, y_val, y_test, preprocessor_path = self.data_transformer.initiate_data_transformation_and_split()\n",
    "\n",
    "        # Apply SMOTE\n",
    "        X_train, y_train = self._apply_smote(X_train, y_train)\n",
    "\n",
    "        best_model = None\n",
    "        best_model_name = None\n",
    "        best_avg_precision = 0\n",
    "        scores = {}\n",
    "\n",
    "        for name, model in self.models.items():\n",
    "            print(f\"\\n[ModelTrainer] Training model: {name}\")\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            y_pred = model.predict(X_val)\n",
    "            if hasattr(model, \"predict_proba\"):\n",
    "                y_proba = model.predict_proba(X_val)[:, 1]\n",
    "            elif hasattr(model, \"decision_function\"):\n",
    "                y_proba = model.decision_function(X_val)\n",
    "            else:\n",
    "                y_proba = y_pred\n",
    "\n",
    "            prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "            rec = recall_score(y_val, y_pred, zero_division=0)\n",
    "            f1 = f1_score(y_val, y_pred, zero_division=0)\n",
    "            roc_auc = roc_auc_score(y_val, y_proba)\n",
    "            avg_prec = average_precision_score(y_val, y_proba)\n",
    "\n",
    "            scores[name] = {\n",
    "                \"precision\": prec,\n",
    "                \"recall\": rec,\n",
    "                \"f1_score\": f1,\n",
    "                \"roc_auc\": roc_auc,\n",
    "                \"average_precision\": avg_prec,\n",
    "            }\n",
    "\n",
    "            print(f\"  Precision:         {prec:.4f}\")\n",
    "            print(f\"  Recall:            {rec:.4f}\")\n",
    "            print(f\"  F1 Score:          {f1:.4f}\")\n",
    "            print(f\"  ROC AUC:           {roc_auc:.4f}\")\n",
    "            print(f\"  Average Precision: {avg_prec:.4f}\")\n",
    "            print(f\"  Classification Report:\\n{classification_report(y_val, y_pred, zero_division=0)}\")\n",
    "            print(\"-\" * 60)\n",
    "\n",
    "            if avg_prec > best_avg_precision:\n",
    "                best_avg_precision = avg_prec\n",
    "                best_model = model\n",
    "                best_model_name = name\n",
    "\n",
    "        print(f\"[ModelTrainer] Best Model: {best_model_name} | Best Average Precision (PR AUC): {best_avg_precision:.4f}\")\n",
    "\n",
    "        if self.config.model_save_path:\n",
    "            save_object(self.config.model_save_path, best_model)\n",
    "            print(f\"[ModelTrainer] Best model saved to: {self.config.model_save_path}\")\n",
    "\n",
    "        return {\n",
    "            \"best_model\": best_model,\n",
    "            \"best_model_name\": best_model_name,\n",
    "            \"best_average_precision\": best_avg_precision,\n",
    "            \"all_scores\": scores,\n",
    "            \"X_train\": X_train,\n",
    "            \"y_train\": y_train,\n",
    "            \"X_val\": X_val,\n",
    "            \"y_val\": y_val,\n",
    "            \"X_test\": X_test,\n",
    "            \"y_test\": y_test,\n",
    "            \"preprocessor_path\": preprocessor_path\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73382f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ModelTrainer:\n",
    "    def __init__(self, config, data_transformer,threshold=0.3):\n",
    "        self.config = config\n",
    "        self.data_transformer = data_transformer\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def train(self):\n",
    "        # Get train/val/test splits from data transformer\n",
    "        (\n",
    "            X_train,   # after preprocessing and SMOTE will be applied here\n",
    "            X_val,\n",
    "            X_test,\n",
    "            y_train,\n",
    "            y_val,\n",
    "            y_test,\n",
    "            preprocessor_path\n",
    "        ) = self.data_transformer.initiate_data_transformation_and_split()\n",
    "\n",
    "        # Apply SMOTE only on training data\n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "        models = {\n",
    "            \"Logistic Regression\": LogisticRegression(random_state=42, max_iter=1000),\n",
    "            \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "            \"XGBClassifier\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
    "            \"CatBoostClassifier\": CatBoostClassifier(verbose=False, random_state=42),\n",
    "            \"LightGBM\": LGBMClassifier(random_state=42, n_jobs=-1),\n",
    "            \"AdaBoost Classifier\": AdaBoostClassifier(random_state=42),\n",
    "            \"Gradient Boosting Classifier\": GradientBoostingClassifier(random_state=42),\n",
    "        }\n",
    "\n",
    "        best_model = None\n",
    "        best_model_name = None\n",
    "        best_auc = 0\n",
    "        scores = {}\n",
    "\n",
    "        for name, model in models.items():\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_val)\n",
    "\n",
    "            if hasattr(model, \"predict_proba\"):\n",
    "                y_proba = model.predict_proba(X_val)[:, 1]\n",
    "            elif hasattr(model, \"decision_function\"):\n",
    "                y_proba = model.decision_function(X_val)\n",
    "            else:\n",
    "                y_proba = y_pred\n",
    "\n",
    "            prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "            rec = recall_score(y_val, y_pred, zero_division=0)\n",
    "            f1 = f1_score(y_val, y_pred, zero_division=0)\n",
    "            try:\n",
    "                auc = roc_auc_score(y_val, y_proba)\n",
    "            except Exception:\n",
    "                auc = 0\n",
    "\n",
    "            scores[name] = {\n",
    "                \"precision\": prec,\n",
    "                \"recall\": rec,\n",
    "                \"f1_score\": f1,\n",
    "                \"roc_auc\": auc,\n",
    "            }\n",
    "\n",
    "            print(f\"[ModelTrainer] {name} Metrics:\")\n",
    "            print(f\"  Precision: {prec:.4f}\")\n",
    "            print(f\"  Recall:    {rec:.4f}\")\n",
    "            print(f\"  F1 Score:  {f1:.4f}\")\n",
    "            print(f\"  ROC AUC:   {auc:.4f}\")\n",
    "            print(f\"  Classification Report:\\n{classification_report(y_val, y_pred, zero_division=0)}\")\n",
    "            print(\"-\" * 60)\n",
    "\n",
    "            if auc > best_auc:\n",
    "                best_auc = auc\n",
    "                best_model = model\n",
    "                best_model_name = name\n",
    "\n",
    "        print(f\"[ModelTrainer] Best Model: {best_model_name} | Best ROC AUC: {best_auc:.4f}\")\n",
    "\n",
    "        if self.config.model_save_path:\n",
    "            save_object(self.config.model_save_path, best_model)\n",
    "            print(f\"[ModelTrainer] Best model saved to: {self.config.model_save_path}\")\n",
    "\n",
    "        return {\n",
    "            \"best_model\": best_model,\n",
    "            \"best_model_name\": best_model_name,\n",
    "            \"best_roc_auc\": best_auc,\n",
    "            \"all_scores\": scores,\n",
    "            \"X_train\": X_train,\n",
    "            \"y_train\": y_train,\n",
    "            \"X_val\": X_val,\n",
    "            \"y_val\": y_val,\n",
    "            \"X_test\": X_test,\n",
    "            \"y_test\": y_test,\n",
    "            \"preprocessor_path\": preprocessor_path\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "908cb5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-04 16:08:53,073: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-07-04 16:08:53,076: INFO: common: created directory at: artifacts]\n",
      "[2025-07-04 16:08:53,078: INFO: common: created directory at: artifacts/data_transformation]\n",
      "[2025-07-04 16:08:53,080: INFO: common: created directory at: artifacts/model_trainer]\n",
      "Transaction Date column after conversion:\n",
      "0   2024-02-20 05:58:41\n",
      "1   2024-02-25 08:09:45\n",
      "2   2024-03-18 03:42:55\n",
      "3   2024-03-16 20:41:31\n",
      "4   2024-01-15 05:08:17\n",
      "Name: Transaction Date, dtype: datetime64[ns]\n",
      "Data type: datetime64[ns]\n",
      "Transaction Date column after conversion:\n",
      "0   2024-03-24 23:42:43\n",
      "1   2024-01-22 00:53:31\n",
      "2   2024-01-22 08:06:03\n",
      "3   2024-01-16 20:34:53\n",
      "4   2024-01-16 15:47:23\n",
      "Name: Transaction Date, dtype: datetime64[ns]\n",
      "Data type: datetime64[ns]\n",
      "[2025-07-04 16:09:09,610: INFO: data_transformation: Building preprocessing pipeline.]\n",
      "[2025-07-04 16:09:09,747: INFO: data_transformation: Applying preprocessing pipeline.]\n",
      "\n",
      "[ModelTrainer] Training model: Logistic Regression\n",
      "  Precision:         0.1792\n",
      "  Recall:            0.6120\n",
      "  F1 Score:          0.2773\n",
      "  ROC AUC:           0.7986\n",
      "  Average Precision: 0.3434\n",
      "  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.85      0.91    279823\n",
      "           1       0.18      0.61      0.28     14768\n",
      "\n",
      "    accuracy                           0.84    294591\n",
      "   macro avg       0.58      0.73      0.59    294591\n",
      "weighted avg       0.94      0.84      0.88    294591\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "[ModelTrainer] Training model: Random Forest\n",
      "  Precision:         0.4498\n",
      "  Recall:            0.2759\n",
      "  F1 Score:          0.3420\n",
      "  ROC AUC:           0.7913\n",
      "  Average Precision: 0.3405\n",
      "  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97    279823\n",
      "           1       0.45      0.28      0.34     14768\n",
      "\n",
      "    accuracy                           0.95    294591\n",
      "   macro avg       0.71      0.63      0.66    294591\n",
      "weighted avg       0.94      0.95      0.94    294591\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "[ModelTrainer] Training model: XGBClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ainao\\anaconda3\\envs\\fraud\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [17:35:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Precision:         0.2006\n",
      "  Recall:            0.5562\n",
      "  F1 Score:          0.2949\n",
      "  ROC AUC:           0.7978\n",
      "  Average Precision: 0.3506\n",
      "  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.88      0.93    279823\n",
      "           1       0.20      0.56      0.29     14768\n",
      "\n",
      "    accuracy                           0.87    294591\n",
      "   macro avg       0.59      0.72      0.61    294591\n",
      "weighted avg       0.94      0.87      0.89    294591\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "[ModelTrainer] Training model: CatBoostClassifier\n",
      "  Precision:         0.2617\n",
      "  Recall:            0.4819\n",
      "  F1 Score:          0.3392\n",
      "  ROC AUC:           0.7944\n",
      "  Average Precision: 0.3500\n",
      "  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95    279823\n",
      "           1       0.26      0.48      0.34     14768\n",
      "\n",
      "    accuracy                           0.91    294591\n",
      "   macro avg       0.62      0.71      0.64    294591\n",
      "weighted avg       0.94      0.91      0.92    294591\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "[ModelTrainer] Training model: LightGBM\n",
      "[LightGBM] [Info] Number of positive: 1119291, number of negative: 1119291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.099141 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3213\n",
      "[LightGBM] [Info] Number of data points in the train set: 2238582, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ainao\\anaconda3\\envs\\fraud\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\ainao\\anaconda3\\envs\\fraud\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Precision:         0.4192\n",
      "  Recall:            0.3526\n",
      "  F1 Score:          0.3830\n",
      "  ROC AUC:           0.8017\n",
      "  Average Precision: 0.3604\n",
      "  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97    279823\n",
      "           1       0.42      0.35      0.38     14768\n",
      "\n",
      "    accuracy                           0.94    294591\n",
      "   macro avg       0.69      0.66      0.68    294591\n",
      "weighted avg       0.94      0.94      0.94    294591\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "[ModelTrainer] Training model: AdaBoost Classifier\n",
      "  Precision:         0.1466\n",
      "  Recall:            0.6553\n",
      "  F1 Score:          0.2396\n",
      "  ROC AUC:           0.8037\n",
      "  Average Precision: 0.3494\n",
      "  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.80      0.88    279823\n",
      "           1       0.15      0.66      0.24     14768\n",
      "\n",
      "    accuracy                           0.79    294591\n",
      "   macro avg       0.56      0.73      0.56    294591\n",
      "weighted avg       0.94      0.79      0.85    294591\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "[ModelTrainer] Training model: Gradient Boosting Classifier\n",
      "  Precision:         0.3070\n",
      "  Recall:            0.4548\n",
      "  F1 Score:          0.3666\n",
      "  ROC AUC:           0.8058\n",
      "  Average Precision: 0.3422\n",
      "  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96    279823\n",
      "           1       0.31      0.45      0.37     14768\n",
      "\n",
      "    accuracy                           0.92    294591\n",
      "   macro avg       0.64      0.70      0.66    294591\n",
      "weighted avg       0.94      0.92      0.93    294591\n",
      "\n",
      "------------------------------------------------------------\n",
      "[ModelTrainer] Best Model: LightGBM | Best Average Precision (PR AUC): 0.3604\n",
      "[ModelTrainer] Best model saved to: artifacts/model_trainer/model.pkl\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_transformation_config = config.get_data_transformation()\n",
    "    data_transformer = DataTransformation(config=data_transformation_config)\n",
    "    model_trainer_config = config.get_model_trainer()\n",
    "    model_trainer = ModelTrainer(config=model_trainer_config, data_transformer=data_transformer)\n",
    "    model_trainer.train()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719847bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22106750",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933953e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94cff05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fraud",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
