{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cdb36e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12850621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\ainao\\\\Downloads\\\\Projects\\\\Fraud Detection\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e78065b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cc733c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\ainao\\\\Downloads\\\\Projects\\\\Fraud Detection'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "934ed4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "@dataclass\n",
    "class ModelTrainerConfig:\n",
    "    root_dir : Path\n",
    "    model_save_path : Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1af68171",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fraud_detection.utils.common import create_directories, read_yaml\n",
    "from fraud_detection.constants import *\n",
    "from fraud_detection.entity import DataTransformationConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41e551e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self, config_filepath=CONFIG_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_transformation(self) -> DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            train_path=config.train_path,\n",
    "            test_path=config.test_path,\n",
    "            train_data=config.train_data,\n",
    "            test_data=config.test_data,\n",
    "            preprocessor=config.preprocessor\n",
    "        )\n",
    "\n",
    "        return data_transformation_config\n",
    "\n",
    "    def get_model_trainer(self) -> ModelTrainerConfig:\n",
    "        config = self.config.model_trainer\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        model_trainer_config = ModelTrainerConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            model_save_path=config.model_save_path\n",
    "        )\n",
    "\n",
    "        return model_trainer_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e00eccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from fraud_detection.entity import DataTransformationConfig\n",
    "from fraud_detection.conponents.data_transformation import DataTransformation\n",
    "from fraud_detection.utils.common import save_object\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73382f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ModelTrainer:\n",
    "    def __init__(self, config, data_transformer):\n",
    "        self.config = config\n",
    "        self.data_transformer = data_transformer\n",
    "\n",
    "    def train(self):\n",
    "        # Get train/val/test splits from data transformer\n",
    "        (\n",
    "            X_train,   # after preprocessing and SMOTE will be applied here\n",
    "            X_val,\n",
    "            X_test,\n",
    "            y_train,\n",
    "            y_val,\n",
    "            y_test,\n",
    "            preprocessor_path\n",
    "        ) = self.data_transformer.initiate_data_transformation_and_split()\n",
    "\n",
    "        # Apply SMOTE only on training data\n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "        models = {\n",
    "            \"Logistic Regression\": LogisticRegression(random_state=42, max_iter=1000),\n",
    "            \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "            \"XGBClassifier\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
    "            \"CatBoostClassifier\": CatBoostClassifier(verbose=False, random_state=42),\n",
    "            \"LightGBM\": LGBMClassifier(random_state=42, n_jobs=-1),\n",
    "            \"AdaBoost Classifier\": AdaBoostClassifier(random_state=42),\n",
    "            \"Gradient Boosting Classifier\": GradientBoostingClassifier(random_state=42),\n",
    "        }\n",
    "\n",
    "        best_model = None\n",
    "        best_model_name = None\n",
    "        best_auc = 0\n",
    "        scores = {}\n",
    "\n",
    "        for name, model in models.items():\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_val)\n",
    "\n",
    "            if hasattr(model, \"predict_proba\"):\n",
    "                y_proba = model.predict_proba(X_val)[:, 1]\n",
    "            elif hasattr(model, \"decision_function\"):\n",
    "                y_proba = model.decision_function(X_val)\n",
    "            else:\n",
    "                y_proba = y_pred\n",
    "\n",
    "            prec = precision_score(y_val, y_pred, zero_division=0)\n",
    "            rec = recall_score(y_val, y_pred, zero_division=0)\n",
    "            f1 = f1_score(y_val, y_pred, zero_division=0)\n",
    "            try:\n",
    "                auc = roc_auc_score(y_val, y_proba)\n",
    "            except Exception:\n",
    "                auc = 0\n",
    "\n",
    "            scores[name] = {\n",
    "                \"precision\": prec,\n",
    "                \"recall\": rec,\n",
    "                \"f1_score\": f1,\n",
    "                \"roc_auc\": auc,\n",
    "            }\n",
    "\n",
    "            print(f\"[ModelTrainer] {name} Metrics:\")\n",
    "            print(f\"  Precision: {prec:.4f}\")\n",
    "            print(f\"  Recall:    {rec:.4f}\")\n",
    "            print(f\"  F1 Score:  {f1:.4f}\")\n",
    "            print(f\"  ROC AUC:   {auc:.4f}\")\n",
    "            print(f\"  Classification Report:\\n{classification_report(y_val, y_pred, zero_division=0)}\")\n",
    "            print(\"-\" * 60)\n",
    "\n",
    "            if auc > best_auc:\n",
    "                best_auc = auc\n",
    "                best_model = model\n",
    "                best_model_name = name\n",
    "\n",
    "        print(f\"[ModelTrainer] Best Model: {best_model_name} | Best ROC AUC: {best_auc:.4f}\")\n",
    "\n",
    "        if self.config.model_save_path:\n",
    "            save_object(self.config.model_save_path, best_model)\n",
    "            print(f\"[ModelTrainer] Best model saved to: {self.config.model_save_path}\")\n",
    "\n",
    "        return {\n",
    "            \"best_model\": best_model,\n",
    "            \"best_model_name\": best_model_name,\n",
    "            \"best_roc_auc\": best_auc,\n",
    "            \"all_scores\": scores,\n",
    "            \"X_train\": X_train,\n",
    "            \"y_train\": y_train,\n",
    "            \"X_val\": X_val,\n",
    "            \"y_val\": y_val,\n",
    "            \"X_test\": X_test,\n",
    "            \"y_test\": y_test,\n",
    "            \"preprocessor_path\": preprocessor_path\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "908cb5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-30 22:35:20,615: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-06-30 22:35:20,620: INFO: common: created directory at: artifacts]\n",
      "[2025-06-30 22:35:20,624: INFO: common: created directory at: artifacts/data_transformation]\n",
      "[2025-06-30 22:35:20,626: INFO: common: created directory at: artifacts/model_trainer]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transaction Date column after conversion:\n",
      "0   2024-02-20 05:58:41\n",
      "1   2024-02-25 08:09:45\n",
      "2   2024-03-18 03:42:55\n",
      "3   2024-03-16 20:41:31\n",
      "4   2024-01-15 05:08:17\n",
      "Name: Transaction Date, dtype: datetime64[ns]\n",
      "Data type: datetime64[ns]\n",
      "Transaction Date column after conversion:\n",
      "0   2024-03-24 23:42:43\n",
      "1   2024-01-22 00:53:31\n",
      "2   2024-01-22 08:06:03\n",
      "3   2024-01-16 20:34:53\n",
      "4   2024-01-16 15:47:23\n",
      "Name: Transaction Date, dtype: datetime64[ns]\n",
      "Data type: datetime64[ns]\n",
      "[2025-06-30 22:35:20,957: INFO: data_transformation: Building preprocessing pipeline.]\n",
      "[2025-06-30 22:35:20,962: INFO: data_transformation: Applying preprocessing pipeline.]\n",
      "[ModelTrainer] Logistic Regression Metrics:\n",
      "  Precision: 0.1458\n",
      "  Recall:    0.6632\n",
      "  F1 Score:  0.2391\n",
      "  ROC AUC:   0.8197\n",
      "  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.81      0.88      1905\n",
      "           1       0.15      0.66      0.24        95\n",
      "\n",
      "    accuracy                           0.80      2000\n",
      "   macro avg       0.56      0.73      0.56      2000\n",
      "weighted avg       0.94      0.80      0.85      2000\n",
      "\n",
      "------------------------------------------------------------\n",
      "[ModelTrainer] Random Forest Metrics:\n",
      "  Precision: 0.3750\n",
      "  Recall:    0.2211\n",
      "  F1 Score:  0.2781\n",
      "  ROC AUC:   0.7867\n",
      "  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      1905\n",
      "           1       0.38      0.22      0.28        95\n",
      "\n",
      "    accuracy                           0.95      2000\n",
      "   macro avg       0.67      0.60      0.62      2000\n",
      "weighted avg       0.93      0.95      0.94      2000\n",
      "\n",
      "------------------------------------------------------------\n",
      "[ModelTrainer] XGBClassifier Metrics:\n",
      "  Precision: 0.4615\n",
      "  Recall:    0.1895\n",
      "  F1 Score:  0.2687\n",
      "  ROC AUC:   0.7803\n",
      "  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97      1905\n",
      "           1       0.46      0.19      0.27        95\n",
      "\n",
      "    accuracy                           0.95      2000\n",
      "   macro avg       0.71      0.59      0.62      2000\n",
      "weighted avg       0.94      0.95      0.94      2000\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ainao\\anaconda3\\envs\\fraud\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [22:35:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ModelTrainer] CatBoostClassifier Metrics:\n",
      "  Precision: 0.5161\n",
      "  Recall:    0.1684\n",
      "  F1 Score:  0.2540\n",
      "  ROC AUC:   0.7943\n",
      "  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      1905\n",
      "           1       0.52      0.17      0.25        95\n",
      "\n",
      "    accuracy                           0.95      2000\n",
      "   macro avg       0.74      0.58      0.61      2000\n",
      "weighted avg       0.94      0.95      0.94      2000\n",
      "\n",
      "------------------------------------------------------------\n",
      "[LightGBM] [Info] Number of positive: 7620, number of negative: 7620\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002437 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3456\n",
      "[LightGBM] [Info] Number of data points in the train set: 15240, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ainao\\anaconda3\\envs\\fraud\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\ainao\\anaconda3\\envs\\fraud\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ModelTrainer] LightGBM Metrics:\n",
      "  Precision: 0.5000\n",
      "  Recall:    0.2000\n",
      "  F1 Score:  0.2857\n",
      "  ROC AUC:   0.7979\n",
      "  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      1905\n",
      "           1       0.50      0.20      0.29        95\n",
      "\n",
      "    accuracy                           0.95      2000\n",
      "   macro avg       0.73      0.60      0.63      2000\n",
      "weighted avg       0.94      0.95      0.94      2000\n",
      "\n",
      "------------------------------------------------------------\n",
      "[ModelTrainer] AdaBoost Classifier Metrics:\n",
      "  Precision: 0.2455\n",
      "  Recall:    0.4316\n",
      "  F1 Score:  0.3130\n",
      "  ROC AUC:   0.8075\n",
      "  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      1905\n",
      "           1       0.25      0.43      0.31        95\n",
      "\n",
      "    accuracy                           0.91      2000\n",
      "   macro avg       0.61      0.68      0.63      2000\n",
      "weighted avg       0.94      0.91      0.92      2000\n",
      "\n",
      "------------------------------------------------------------\n",
      "[ModelTrainer] Gradient Boosting Classifier Metrics:\n",
      "  Precision: 0.3704\n",
      "  Recall:    0.2105\n",
      "  F1 Score:  0.2685\n",
      "  ROC AUC:   0.8262\n",
      "  Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      1905\n",
      "           1       0.37      0.21      0.27        95\n",
      "\n",
      "    accuracy                           0.95      2000\n",
      "   macro avg       0.67      0.60      0.62      2000\n",
      "weighted avg       0.93      0.95      0.94      2000\n",
      "\n",
      "------------------------------------------------------------\n",
      "[ModelTrainer] Best Model: Gradient Boosting Classifier | Best ROC AUC: 0.8262\n",
      "[ModelTrainer] Best model saved to: artifacts/model_trainer/model.pkl\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_transformation_config = config.get_data_transformation()\n",
    "    data_transformer = DataTransformation(config=data_transformation_config)\n",
    "    model_trainer_config = config.get_model_trainer()\n",
    "    model_trainer = ModelTrainer(config=model_trainer_config, data_transformer=data_transformer)\n",
    "    model_trainer.train()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719847bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22106750",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933953e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94cff05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fraud",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
